{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "09032073",
   "metadata": {},
   "source": [
    "## Importing Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0d7f51b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\abine\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\abine\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package cmudict to\n",
      "[nltk_data]     C:\\Users\\abine\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package cmudict is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.tokenize import word_tokenize\n",
    "from textblob import TextBlob\n",
    "from nltk.corpus import cmudict \n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('cmudict')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "447549de",
   "metadata": {},
   "source": [
    "* Imports the pandas library, which is a powerful tool for data manipulation and analysis in Python. It's widely used for handling and analyzing data structures like data frames.\n",
    "\n",
    "* The requests library is used for making HTTP requests in Python. It allows you to send HTTP requests to a specified URL and get the response back, which can be useful for web scraping and interacting with APIs.\n",
    "\n",
    "* BeautifulSoup is a library used for parsing HTML and XML documents. It creates a parse tree for parsed pages that can be used to extract data from HTML, which is useful for web scraping.\n",
    "\n",
    "* NLTK (Natural Language Toolkit) is a comprehensive library for natural language processing (NLP) in Python. It provides tools for working with human language data, including tokenization, tagging, parsing, and semantic reasoning.\n",
    "\n",
    "* This line imports the stopwords module from NLTK, which provides a list of common words that are usually filtered out in text processing, such as 'the', 'is', and 'in'.\n",
    "\n",
    "* The string module provides a collection of string operations and constants. It is useful for tasks such as removing punctuation from text.\n",
    "\n",
    "* Importing the sent_tokenize function from NLTK, which is used to split text into sentences.\n",
    "\n",
    "* Importing the word_tokenize function from NLTK, which is used to split text into words (tokens).\n",
    "\n",
    "* TextBlob is a library for processing textual data. It provides a simple API for common NLP tasks such as part-of-speech tagging, noun phrase extraction, sentiment analysis, classification, translation, and more.\n",
    "\n",
    "* Importing the cmudict module from NLTK, which is a pronouncing dictionary that can be used to find the number of syllables in a word, among other phonetic information.\n",
    "\n",
    "* Downloading the 'punkt' package from NLTK, which includes pre-trained models for tokenizing text into sentences and words.\n",
    "\n",
    "* Downloading the 'stopwords' corpus from NLTK, which contains lists of common stopwords for various languages.\n",
    "\n",
    "* Downloading the 'cmudict' corpus from NLTK, which is the Carnegie Mellon University Pronouncing Dictionary, useful for phonetic and syllable analysis of words."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb65767",
   "metadata": {},
   "source": [
    "## Importing the Input Data and Assigning it to a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da7a3a64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL_ID</th>\n",
       "      <th>URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bctech2011</td>\n",
       "      <td>https://insights.blackcoffer.com/ml-and-ai-bas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bctech2012</td>\n",
       "      <td>https://insights.blackcoffer.com/streamlined-i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bctech2013</td>\n",
       "      <td>https://insights.blackcoffer.com/efficient-dat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bctech2014</td>\n",
       "      <td>https://insights.blackcoffer.com/effective-man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bctech2015</td>\n",
       "      <td>https://insights.blackcoffer.com/streamlined-t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>bctech2153</td>\n",
       "      <td>https://insights.blackcoffer.com/population-an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>bctech2154</td>\n",
       "      <td>https://insights.blackcoffer.com/google-lsa-ap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>bctech2155</td>\n",
       "      <td>https://insights.blackcoffer.com/healthcare-da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>bctech2156</td>\n",
       "      <td>https://insights.blackcoffer.com/budget-sales-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>bctech2157</td>\n",
       "      <td>https://insights.blackcoffer.com/amazon-buy-bo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>147 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         URL_ID                                                URL\n",
       "0    bctech2011  https://insights.blackcoffer.com/ml-and-ai-bas...\n",
       "1    bctech2012  https://insights.blackcoffer.com/streamlined-i...\n",
       "2    bctech2013  https://insights.blackcoffer.com/efficient-dat...\n",
       "3    bctech2014  https://insights.blackcoffer.com/effective-man...\n",
       "4    bctech2015  https://insights.blackcoffer.com/streamlined-t...\n",
       "..          ...                                                ...\n",
       "142  bctech2153  https://insights.blackcoffer.com/population-an...\n",
       "143  bctech2154  https://insights.blackcoffer.com/google-lsa-ap...\n",
       "144  bctech2155  https://insights.blackcoffer.com/healthcare-da...\n",
       "145  bctech2156  https://insights.blackcoffer.com/budget-sales-...\n",
       "146  bctech2157  https://insights.blackcoffer.com/amazon-buy-bo...\n",
       "\n",
       "[147 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_file = 'Input.xlsx'\n",
    "\n",
    "df = pd.read_excel('C:/Users/abine/Desktop/Jupyter Notebook/BlackCoffer Project/Input.xlsx', header=0)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0541b94e",
   "metadata": {},
   "source": [
    "## Defining Functions for Text Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "121203b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract article title from URL\n",
    "def extract_article_title(url):\n",
    "    try:\n",
    "        # Use requests to fetch webpage content\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "        html = response.text\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        \n",
    "        # Extract article title\n",
    "        article_title = soup.find('title').text.strip() if soup.find('title') else ''\n",
    "        \n",
    "        # Remove '- Blackcoffer Insights' from the end of the title\n",
    "        if article_title.endswith('- Blackcoffer Insights'):\n",
    "            article_title = article_title.replace('- Blackcoffer Insights', '').strip()\n",
    "        \n",
    "        return article_title\n",
    "    \n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error fetching URL: {url}. Exception: {e}\")\n",
    "        return None\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting article title from URL: {url}. Exception: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ab675d",
   "metadata": {},
   "source": [
    "The function extract_article_title(url) retrieves and processes the title of a webpage given its URL.\n",
    "\n",
    "* Fetch Webpage Content:\n",
    "Uses the requests library to get the HTML content of the webpage.\n",
    "Raises an exception if the HTTP request fails.\n",
    "\n",
    "* Parse HTML:\n",
    "Uses BeautifulSoup to parse the HTML content of the webpage.\n",
    "\n",
    "* Extract Title:\n",
    "Finds and extracts the text within the <title> tag.\n",
    "Strips any leading/trailing whitespace from the title.\n",
    "    \n",
    "* Remove Specific Suffix:\n",
    "If the title ends with '- Blackcoffer Insights', this suffix is removed.\n",
    "    \n",
    "* Error Handling:\n",
    "Catches and prints exceptions related to HTTP requests and other potential errors during extraction.\n",
    "Returns None in case of an error."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab8fea7d",
   "metadata": {},
   "source": [
    "## Creating a list of Positive and Negative Words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e205e9e",
   "metadata": {},
   "source": [
    "### Positive Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05156ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample Positive Dictionary\n",
    "positive_dictionary = [\"a+\", \"abound\", \"abounds\", \"abundance\", \"abundant\", \"accessable\", \"accessible\", \n",
    "    \"acclaim\", \"acclaimed\", \"acclamation\", \"accolade\", \"accolades\", \"accommodative\", \n",
    "    \"accomodative\", \"accomplish\", \"accomplished\", \"accomplishment\", \"accomplishments\", \n",
    "    \"accurate\", \"accurately\", \"achievable\", \"achievement\", \"achievements\", \"achievible\", \n",
    "    \"acumen\", \"adaptable\", \"adaptive\", \"adequate\", \"adjustable\", \"admirable\", \"admirably\", \n",
    "    \"admiration\", \"admire\", \"admired\", \"admires\", \"admiring\", \"admiringly\", \"adorable\", \n",
    "    \"adore\", \"adored\", \"adorer\", \"adoring\", \"adoringly\", \"adroit\", \"adroitly\", \"adulate\", \n",
    "    \"adulation\", \"adulatory\", \"advanced\", \"advantage\", \"advantageous\", \"advantageously\", \n",
    "    \"advantages\", \"adventuresome\", \"adventurous\", \"advocate\", \"advocated\", \"advocates\", \n",
    "    \"affability\", \"affable\", \"affably\", \"affectation\", \"affection\", \"affectionate\", \n",
    "    \"affinity\", \"affirm\", \"affirmation\", \"affirmative\", \"affluence\", \"affluent\", \n",
    "    \"afford\", \"affordable\", \"affordably\", \"afordable\", \"agile\", \"agilely\", \"agility\", \n",
    "    \"agreeable\", \"agreeableness\", \"agreeably\", \"all-around\", \"alluring\", \"alluringly\", \n",
    "    \"altruistic\", \"altruistically\", \"amaze\", \"amazed\", \"amazement\", \"amazes\", \"amazing\", \n",
    "    \"amazingly\", \"ambitious\", \"ambitiously\", \"ameliorate\", \"amenable\", \"amenity\", \n",
    "    \"amiability\", \"amiabily\", \"amiable\", \"amicability\", \"amicable\", \"amicably\", \n",
    "    \"amity\", \"ample\", \"amply\", \"amuse\", \"amusing\", \"amusingly\", \"angel\", \"angelic\", \n",
    "    \"apotheosis\", \"appeal\", \"appealing\", \"applaud\", \"appreciable\", \"appreciate\", \n",
    "    \"appreciated\", \"appreciates\", \"appreciative\", \"appreciatively\", \"appropriate\", \n",
    "    \"approval\", \"approve\", \"ardent\", \"ardently\", \"ardor\", \"articulate\", \"aspiration\", \n",
    "    \"aspirations\", \"aspire\", \"assurance\", \"assurances\", \"assure\", \"assuredly\", \n",
    "    \"assuring\", \"astonish\", \"astonished\", \"astonishing\", \"astonishingly\", \"astonishment\", \n",
    "    \"astound\", \"astounded\", \"astounding\", \"astoundingly\", \"astutely\", \"attentive\", \n",
    "    \"attraction\", \"attractive\", \"attractively\", \"attune\", \"audible\", \"audibly\", \n",
    "    \"auspicious\", \"authentic\", \"authoritative\", \"autonomous\", \"available\", \"aver\", \n",
    "    \"avid\", \"avidly\", \"award\", \"awarded\", \"awards\", \"awe\", \"awed\", \"awesome\", \"awesomely\", \n",
    "    \"awesomeness\", \"awestruck\", \"awsome\", \"backbone\", \"balanced\", \"bargain\", \"beauteous\", \n",
    "    \"beautiful\", \"beautifullly\", \"beautifully\", \"beautify\", \"beauty\", \"beckon\", \"beckoned\", \n",
    "    \"beckoning\", \"beckons\", \"believable\", \"believeable\", \"beloved\", \"benefactor\", \n",
    "    \"beneficent\", \"beneficial\", \"beneficially\", \"beneficiary\", \"benefit\", \"benefits\", \n",
    "    \"benevolence\", \"benevolent\", \"benifits\", \"best\", \"best-known\", \"best-performing\", \n",
    "    \"best-selling\", \"better\", \"better-known\", \"better-than-expected\", \"beutifully\", \n",
    "    \"blameless\", \"bless\", \"blessing\", \"bliss\", \"blissful\", \"blissfully\", \"blithe\", \n",
    "    \"blockbuster\", \"bloom\", \"blossom\", \"bolster\", \"bonny\", \"bonus\", \"bonuses\", \"boom\", \n",
    "    \"booming\", \"boost\", \"boundless\", \"bountiful\", \"brainiest\", \"brainy\", \"brand-new\", \n",
    "    \"brave\", \"bravery\", \"bravo\", \"breakthrough\", \"breakthroughs\", \"breathlessness\", \n",
    "    \"breathtaking\", \"breathtakingly\", \"breeze\", \"bright\", \"brighten\", \"brighter\", \n",
    "    \"brightest\", \"brilliance\", \"brilliances\", \"brilliant\", \"brilliantly\", \"brisk\", \n",
    "    \"brotherly\", \"bullish\", \"buoyant\", \"cajole\", \"calm\", \"calming\", \"calmness\", \n",
    "    \"capability\", \"capable\", \"capably\", \"captivate\", \"captivating\", \"carefree\", \n",
    "    \"cashback\", \"cashbacks\", \"catchy\", \"celebrate\", \"celebrated\", \"celebration\", \n",
    "    \"celebratory\", \"champ\", \"champion\", \"charisma\", \"charismatic\", \"charitable\", \n",
    "    \"charm\", \"charming\", \"charmingly\", \"chaste\", \"cheaper\", \"cheapest\", \"cheer\", \n",
    "    \"cheerful\", \"cheery\", \"cherish\", \"cherished\", \"cherub\", \"chic\", \"chivalrous\", \n",
    "    \"chivalry\", \"civility\", \"civilize\", \"clarity\", \"classic\", \"classy\", \"clean\", \n",
    "    \"cleaner\", \"cleanest\", \"cleanliness\", \"cleanly\", \"clear\", \"clear-cut\", \"cleared\", \n",
    "    \"clearer\", \"clearly\", \"clears\", \"clever\", \"cleverly\", \"cohere\", \"coherence\", \n",
    "    \"coherent\", \"cohesive\", \"colorful\", \"comely\", \"comfort\", \"comfortable\", \"comfortably\", \n",
    "    \"comforting\", \"comfy\", \"commend\", \"commendable\", \"commendably\", \"commitment\", \n",
    "    \"commodious\", \"compact\", \"compactly\", \"compassion\", \"compassionate\", \"compatible\", \n",
    "    \"competitive\", \"complement\", \"complementary\", \"complemented\", \"complements\", \n",
    "    \"compliant\", \"compliment\", \"complimentary\", \"comprehensive\", \"conciliate\", \n",
    "    \"conciliatory\", \"concise\", \"confidence\", \"confident\", \"congenial\", \"congratulate\", \n",
    "    \"congratulation\", \"congratulations\", \"congratulatory\", \"conscientious\", \"considerate\", \n",
    "    \"consistent\", \"consistently\", \"constructive\", \"consummate\", \"contentment\", \"continuity\", \n",
    "    \"contrasty\", \"contribution\", \"convenience\", \"convenient\", \"conveniently\", \"convience\", \n",
    "    \"convienient\", \"convient\", \"convincing\", \"convincingly\", \"cool\", \"coolest\", \"cooperative\", \n",
    "    \"cooperatively\", \"cornerstone\", \"correct\", \"correctly\", \"cost-effective\", \"cost-saving\", \n",
    "    \"counter-attack\", \"counter-attacks\", \"courage\", \"courageous\", \"courageously\", \"courageousness\", \n",
    "    \"courteous\", \"courtly\", \"covenant\", \"cozy\", \"creative\", \"credence\", \"credible\", \"crisp\", \n",
    "    \"crisper\", \"cure\", \"cure-all\", \"cushy\", \"cute\", \"cuteness\", \"danke\", \"danken\", \"daring\", \n",
    "    \"daringly\", \"darling\", \"dashing\", \"dauntless\", \"dawn\", \"dazzle\", \"dazzled\", \"dazzling\", \n",
    "    \"dead-cheap\", \"dead-on\", \"decency\", \"decent\", \"decisive\", \"decisiveness\", \"dedicated\", \n",
    "    \"defeat\", \"defeated\", \"defeating\", \"defeats\", \"defender\", \"deference\", \"deft\", \"deginified\", \n",
    "    \"delectable\", \"delicacy\", \"delicate\", \"delicious\", \"delight\", \"delighted\", \"delightful\", \n",
    "    \"delightfully\", \"delightfulness\", \"dependable\", \"dependably\", \"deservedly\", \"deserving\", \n",
    "    \"desirable\", \"desiring\", \"desirous\", \"destiny\", \"detachable\", \"devout\", \"dexterous\", \n",
    "    \"dexterously\", \"dextrous\", \"dignified\", \"dignify\", \"dignity\", \"diligence\", \"diligent\", \n",
    "    \"diligently\", \"diplomatic\", \"dirt-cheap\", \"distinction\", \"distinctive\", \"distinguished\", \n",
    "    \"diversified\", \"divine\", \"divinely\", \"dominate\", \"dominated\", \"dominates\", \"dote\", \"dotingly\", \n",
    "    \"doubtless\", \"dreamland\", \"dumbfounded\", \"dumbfounding\", \"dummy-proof\", \"durable\", \"dynamic\", \n",
    "    \"eager\", \"eagerly\", \"eagerness\", \"earnest\", \"earnestly\", \"earnestness\", \"ease\", \"eased\", \n",
    "    \"eases\", \"easier\", \"easiest\", \"easiness\", \"easing\", \"easy\", \"easy-to-use\", \"easygoing\", \n",
    "    \"ebullience\", \"ebullient\", \"ebulliently\", \"ecenomical\", \"economical\", \"ecstasies\", \n",
    "    \"ecstasy\", \"ecstatic\", \"ecstatically\", \"edify\", \"educated\", \"effective\", \"effectively\", \n",
    "    \"effectiveness\", \"effectual\", \"efficacious\", \"efficient\", \"efficiently\", \"effortless\", \n",
    "    \"effortlessly\", \"effusion\", \"effusive\", \"effusively\", \"effusiveness\", \"elan\", \"elate\", \n",
    "    \"elated\", \"elatedly\", \"elation\", \"electrify\", \"elegance\", \"elegant\", \"elegantly\", \n",
    "    \"elevate\", \"elite\", \"eloquence\", \"eloquent\", \"eloquently\", \"embolden\", \"eminence\", \n",
    "    \"eminent\", \"empathize\", \"empathy\", \"empower\", \"empowerment\", \"enchant\", \"enchanted\", \n",
    "    \"enchanting\", \"enchantingly\", \"encourage\", \"encouragement\", \"encouraging\", \n",
    "    \"encouragingly\", \"endear\", \"endearing\", \"endorse\", \"endorsed\", \"endorsement\", \n",
    "    \"endorses\", \"endorsing\", \"energetic\", \"energize\", \"energy-efficient\", \"energy-saving\", \n",
    "    \"engaging\", \"engrossing\", \"enhance\", \"enhanced\", \"enhancement\", \"enhances\", \"enjoy\", \n",
    "    \"enjoyable\", \"enjoyably\", \"enjoyed\", \"enjoying\", \"enjoyment\", \"enjoys\", \"enlighten\", \n",
    "    \"enlightenment\", \"enliven\", \"ennoble\", \"enough\", \"enrapt\", \"enrapture\", \"enraptured\", \n",
    "    \"enrich\", \"enrichment\", \"enterprising\", \"entertain\", \"entertaining\", \"entertains\", \n",
    "    \"enthral\", \"enthrall\", \"enthralled\", \"enthuse\", \"enthusiasm\", \"enthusiast\", \n",
    "    \"enthusiastic\", \"enthusiastically\", \"entice\", \"enticed\", \"enticing\", \"enticingly\", \n",
    "    \"entranced\", \"entrancing\", \"entrust\", \"enviable\", \"enviably\", \"envious\", \"enviously\", \n",
    "    \"enviousness\", \"envy\", \"equitable\", \"ergonomical\", \"err-free\", \"erudite\", \"ethical\", \n",
    "    \"eulogize\", \"euphoria\", \"euphoric\", \"euphorically\", \"evaluative\", \"evenly\", \"eventful\", \n",
    "    \"everlasting\", \"evocative\", \"exalt\", \"exaltation\", \"exalted\", \"exaltedly\", \"exalting\", \n",
    "    \"exaltingly\", \"examplar\", \"examplary\", \"exceed\", \"exceeded\", \"exceeding\", \"exceedingly\", \n",
    "    \"exceeds\", \"excel\", \"exceled\", \"excelent\", \"excellant\", \"excelled\", \"excellence\", \n",
    "    \"excellency\", \"excellent\", \"excellently\", \"excels\", \"exceptional\", \"exceptionally\", \n",
    "    \"excite\", \"excited\", \"excitedly\", \"excitedness\", \"excitement\", \"excites\", \"exciting\", \n",
    "    \"excitingly\", \"exellent\", \"exemplar\", \"exemplary\", \"exhilarate\", \"exhilarating\", \n",
    "    \"exhilaratingly\", \"exhilaration\", \"exonerate\", \"expansive\", \"expeditiously\", \"expertly\", \n",
    "    \"exquisite\", \"exquisitely\", \"extol\", \"extoll\", \"extraordinarily\", \"extraordinary\", \n",
    "    \"exuberance\", \"exuberant\", \"exuberantly\", \"exult\", \"exultant\", \"exultation\", \"exultingly\", \n",
    "    \"eye-catch\", \"eye-catching\", \"eyecatch\", \"eyecatching\", \"fabulous\", \"fabulously\", \"facilitate\", \n",
    "    \"fair\", \"fairly\", \"fairness\", \"faith\", \"faithful\", \"faithfully\", \"faithfulness\", \"fame\", \"famed\", \n",
    "    \"famous\", \"famously\", \"fancier\", \"fancinating\", \"fancy\", \"fanfare\", \"fans\", \"fantastic\", \n",
    "    \"fantastically\", \"fascinate\", \"fascinating\", \"fascinatingly\", \"fascination\", \"fashionable\", \n",
    "    \"fashionably\", \"fast\", \"fast-growing\", \"fast-paced\", \"faster\", \"fastest\", \"fastest-growing\", \n",
    "    \"faultless\", \"fav\", \"fave\", \"favor\", \"favorable\", \"favored\", \"favorite\", \"favorited\", \"favour\", \n",
    "    \"fearless\", \"fearlessly\", \"feasible\", \"feasibly\", \"feat\", \"feature-rich\", \"fecilitous\", \"feisty\", \n",
    "    \"felicitate\", \"felicitous\", \"felicity\", \"fertile\", \"fervent\", \"fervently\", \"fervid\", \"fervidly\", \n",
    "    \"fervor\", \"festive\", \"fidelity\", \"fiery\", \"fine\", \"fine-looking\", \"finely\", \"finer\", \"finest\", \n",
    "    \"firmer\", \"first-class\", \"first-in-class\", \"first-rate\", \"flashy\", \"flatter\", \"flattering\", \n",
    "    \"flatteringly\", \"flawless\", \"flawlessly\", \"flexibility\", \"flexible\", \"flourish\", \"flourishing\", \n",
    "    \"fluent\", \"flutter\", \"fond\", \"fondly\", \"fondness\", \"foolproof\", \"foremost\", \"foresight\", \n",
    "    \"formidable\", \"fortitude\", \"fortuitous\", \"fortuitously\", \"fortunate\", \"fortunately\", \n",
    "    \"fortune\", \"fragrant\", \"free\", \"freed\", \"freedom\", \"freedoms\", \"fresh\", \"fresher\", \"freshest\", \n",
    "    \"friendliness\", \"friendly\", \"frolic\", \"frugal\", \"fruitful\", \"ftw\", \"fulfillment\", \"fun\", \n",
    "    \"futurestic\", \"futuristic\", \"gaiety\", \"gaily\", \"gain\", \"gained\", \"gainful\", \"gainfully\", \n",
    "    \"gaining\", \"gains\", \"gallant\", \"gallantly\", \"galore\", \"geekier\", \"geeky\", \"gem\", \"gems\", \n",
    "    \"generosity\", \"generous\", \"generously\", \"genial\", \"genius\", \"gentle\", \"gentlest\", \n",
    "    \"genuine\", \"gifted\", \"glad\", \"gladden\", \"gladly\", \"gladness\", \"glamorous\", \"glee\", \n",
    "    \"gleeful\", \"gleefully\", \"glimmer\", \"glimmering\", \"glisten\", \"glistening\", \"glitter\", \n",
    "    \"glitz\", \"glorify\", \"glorious\", \"gloriously\", \"glory\", \"glow\", \"glowing\", \"glowingly\", \n",
    "    \"god-given\", \"god-send\", \"godlike\", \"godsend\", \"gold\", \"golden\", \"good\", \"goodly\", \n",
    "    \"goodness\", \"goodwill\", \"goood\", \"gooood\", \"gorgeous\", \"gorgeously\", \"grace\", \n",
    "    \"graceful\", \"gracefully\", \"gracious\", \"graciously\", \"graciousness\", \"grand\", \"grandeur\", \n",
    "    \"grateful\", \"gratefully\", \"gratification\", \"gratified\", \"gratifies\", \"gratify\", \n",
    "    \"gratifying\", \"gratifyingly\", \"gratitude\", \"great\", \"greatest\", \"greatness\", \"grin\", \n",
    "    \"groundbreaking\", \"guarantee\", \"guidance\", \"guiltless\", \"gumption\", \"gush\", \"gusto\", \n",
    "    \"gutsy\", \"hail\", \"halcyon\", \"hale\", \"hallmark\", \"hallmarks\", \"hallowed\", \"handier\", \n",
    "    \"handily\", \"hands-down\", \"handsome\", \"handsomely\", \"handy\", \"happier\", \"happily\", \n",
    "    \"happiness\", \"happy\", \"hard-working\", \"hardier\", \"hardy\", \"harmless\", \"harmonious\", \n",
    "    \"harmoniously\", \"harmonize\", \"harmony\", \"headway\", \"heal\", \"healthful\", \"healthy\", \n",
    "    \"hearten\", \"heartening\", \"heartfelt\", \"heartily\", \"heartwarming\", \"heaven\", \"heavenly\", \n",
    "    \"helped\", \"helpful\", \"helping\", \"hero\", \"heroic\", \"heroically\", \"heroine\", \"heroize\", \n",
    "    \"heros\", \"high-quality\", \"high-spirited\", \"hilarious\", \"holy\", \"homage\", \"honest\", \n",
    "    \"honesty\", \"honor\", \"honorable\", \"honored\", \"honoring\", \"hooray\", \"hopeful\", \n",
    "    \"hopefully\", \"hopefulness\", \"hopes\", \"hoping\", \"hospitable\", \"hot\", \"hotcake\", \n",
    "    \"hotcakes\", \"hottest\", \"hug\", \"humane\", \"humble\", \"humility\", \"humor\", \"humorous\", \n",
    "    \"humorously\", \"humour\", \"humourous\", \"ideal\", \"idealize\", \"ideally\", \"idol\", \n",
    "    \"idolize\", \"idolized\", \"idyllic\", \"illuminate\", \"illuminati\", \"illuminating\", \n",
    "    \"illumine\", \"illustrious\", \"ilu\", \"imaculate\", \"imaginative\", \"immaculate\", \n",
    "    \"immaculately\", \"immense\", \"impartial\", \"impartiality\", \"impartially\", \"impassioned\", \n",
    "    \"impeccable\", \"impeccably\", \"important\", \"impress\", \"impressed\", \"impresses\", \n",
    "    \"impressive\", \"impressively\", \"impressiveness\", \"improve\", \"improved\", \"improvement\", \n",
    "    \"improvements\", \"improves\", \"improving\", \"incredible\", \"incredibly\", \"indebted\", \n",
    "    \"individualized\", \"indulgence\", \"indulgent\", \"industrious\", \"inestimable\", \"inestimably\", \n",
    "    \"inexpensive\", \"infallibility\", \"infallible\", \"infallibly\", \"influential\", \"ingenious\", \n",
    "    \"ingeniously\", \"ingenuity\", \"ingenuous\", \"ingenuously\", \"innocuous\", \"innovation\", \n",
    "    \"innovative\", \"inpressed\", \"insightful\", \"insightfully\", \"inspiration\", \"inspirational\", \n",
    "    \"inspire\", \"inspiring\", \"instantly\", \"instructive\", \"instrumental\", \"integral\", \n",
    "    \"integrated\", \"intelligence\", \"intelligent\", \"intelligible\", \"interesting\", \n",
    "    \"interests\", \"intimacy\", \"intimate\", \"intricate\", \"intrigue\", \"intriguing\", \n",
    "    \"intriguingly\", \"intuitive\", \"invaluable\", \"invaluablely\", \"inventive\", \"invigorate\", \n",
    "    \"invigorating\", \"invincibility\", \"invincible\", \"inviolable\", \"inviolate\", \"invulnerable\", \n",
    "    \"irreplaceable\", \"irreproachable\", \"irresistible\", \"irresistibly\", \"issue-free\", \"jaw-droping\", \n",
    "    \"jaw-dropping\", \"jollify\", \"jolly\", \"jovial\", \"joy\", \"joyful\", \"joyfully\", \"joyous\", \"joyously\", \n",
    "    \"jubilant\", \"jubilantly\", \"jubilate\", \"jubilation\", \"jubiliant\", \"judicious\", \"justly\", \"keen\", \n",
    "    \"keenly\", \"keenness\", \"kid-friendly\", \"kindliness\", \"kindly\", \"kindness\", \"knowledgeable\", \n",
    "    \"kudos\", \"large-capacity\", \"laud\", \"laudable\", \"laudably\", \"lavish\", \"lavishly\", \"law-abiding\", \n",
    "    \"lawful\", \"lawfully\", \"lead\", \"leading\", \"leads\", \"lean\", \"led\", \"legendary\", \"leverage\", \n",
    "    \"levity\", \"liberate\", \"liberation\", \"liberty\", \"lifesaver\", \"light-hearted\", \"lighter\", \n",
    "    \"likable\", \"like\", \"liked\", \"likes\", \"liking\", \"lionhearted\", \"lively\", \"logical\", \"long-lasting\", \n",
    "    \"lovable\", \"lovably\", \"love\", \"loved\", \"loveliness\", \"lovely\", \"lover\", \"loves\", \"loving\", \n",
    "    \"low-cost\", \"low-price\", \"low-priced\", \"low-risk\", \"lower-priced\", \"loyal\", \"loyalty\", \"lucid\", \n",
    "    \"lucidly\", \"luck\", \"luckier\", \"luckiest\", \"luckiness\", \"lucky\", \"lucrative\", \"luminous\", \n",
    "    \"lush\", \"luster\", \"lustrous\", \"luxuriant\", \"luxuriate\", \"luxurious\", \"luxuriously\", \n",
    "    \"luxury\", \"lyrical\", \"magic\", \"magical\", \"magnanimous\", \"magnanimously\", \"magnetic\", \n",
    "    \"magnificence\", \"magnificent\", \"magnificently\", \"majestic\", \"majesty\", \"manageable\", \n",
    "    \"manifest\", \"manly\", \"mannerly\", \"marvel\", \"marveled\", \"marvelled\", \"marvellous\", \n",
    "    \"marvelous\", \"marvelously\", \"marvelousness\", \"marvels\", \"master\", \"masterful\", \n",
    "    \"masterfully\", \"masterpiece\", \"masterpieces\", \"masters\", \"mastery\", \"matchless\", \n",
    "    \"mature\", \"maturely\", \"maturity\", \"meaningful\", \"memorable\", \"merciful\", \"mercifully\", \n",
    "    \"mercy\", \"merit\", \"meritorious\", \"merrily\", \"merriment\", \"merriness\", \"merry\", \"mesmerize\", \n",
    "    \"mesmerized\", \"mesmerizes\", \"mesmerizing\", \"mesmerizingly\", \"meticulous\", \"meticulously\", \n",
    "    \"mightily\", \"mighty\", \"mind-blowing\", \"miracle\", \"miracles\", \"miraculous\", \"miraculously\", \n",
    "    \"miraculousness\", \"modern\", \"modest\", \"modesty\", \"momentous\", \"monumental\", \"monumentally\", \n",
    "    \"morality\", \"motivated\", \"multi-purpose\", \"navigable\", \"neat\", \"neatest\", \"neatly\", \"nice\", \n",
    "    \"nicely\", \"nicer\", \"nicest\", \"nifty\", \"nimble\", \"noble\", \"nobly\", \"noiseless\", \"non-violence\", \n",
    "    \"non-violent\", \"notably\", \"noteworthy\", \"nourish\", \"nourishing\", \"nourishment\", \"novelty\", \n",
    "    \"nurturing\", \"oasis\", \"obsession\", \"obsessions\", \"obtainable\", \"openly\", \"openness\", \"optimal\", \n",
    "    \"optimism\", \"optimistic\", \"opulent\", \"orderly\", \"originality\", \"outdo\", \"outdone\", \"outperform\", \n",
    "    \"outperformed\", \"outperforming\", \"outperforms\", \"outstanding\", \"outstandingly\", \"outshine\", \n",
    "    \"outshone\", \"outsmart\", \"outstanding\", \"ovation\", \"overjoyed\", \"overtake\", \"overtaken\", \n",
    "    \"overtakes\", \"overtaking\", \"overtook\", \"overture\", \"pain-free\", \"painless\", \"painlessly\", \n",
    "    \"palatial\", \"pamper\", \"pampered\", \"pamperedly\", \"pamperedness\", \"pampers\", \"panoramic\", \n",
    "    \"paradise\", \"paramount\", \"pardon\", \"passion\", \"passionate\", \"passionately\", \"patience\", \n",
    "    \"patient\", \"patiently\", \"patriot\", \"patriotic\", \"peace\", \"peaceable\", \"peaceful\", \"peacefully\", \n",
    "    \"peacekeepers\", \"peach\", \"peerless\", \"pep\", \"pepped\", \"pepping\", \"peppy\", \"peps\", \"perfect\", \n",
    "    \"perfection\", \"perfectly\", \"permissible\", \"perseverance\", \"persevere\", \"personages\", \n",
    "    \"personalized\", \"phenomenal\", \"phenomenally\", \"picturesque\", \"piety\", \"pinnacle\", \"playful\", \n",
    "    \"playfully\", \"pleasant\", \"pleasantly\", \"pleased\", \"pleases\", \"pleasing\", \"pleasingly\", \n",
    "    \"pleasurable\", \"pleasurably\", \"pleasure\", \"plentiful\", \"pluses\", \"plush\", \"plusses\", \n",
    "    \"poetic\", \"poeticize\", \"poignant\", \"poise\", \"poised\", \"polished\", \"polite\", \"politely\", \n",
    "    \"popular\", \"portable\", \"posh\", \"positive\", \"positively\", \"positives\", \"powerful\", \"powerfully\", \n",
    "    \"praise\", \"praiseworthy\", \"praising\", \"pre-eminent\", \"precious\", \"precise\", \"precisely\", \n",
    "    \"preeminent\", \"prefer\", \"preferable\", \"preferably\", \"prefered\", \"preferes\", \"preferring\", \n",
    "    \"prefers\", \"premier\", \"prestige\", \"prestigious\", \"prettily\", \"pretty\", \"priceless\", \"pride\", \n",
    "    \"principled\", \"privilege\", \"privileged\", \"prize\", \"proactive\", \"problem-free\", \"problem-solver\", \n",
    "    \"prodigious\", \"prodigiously\", \"prodigy\", \"productive\", \"productively\", \"proficient\", \"proficiently\", \n",
    "    \"profound\", \"profoundly\", \"profuse\", \"profusion\", \"progress\", \"progressive\", \"prolific\", \"prominent\", \n",
    "    \"prominence\", \"promise\", \"promised\", \"promises\", \"promising\", \"promoter\", \"prompt\", \"promptly\", \n",
    "    \"proper\", \"properly\", \"propitious\", \"propitiously\", \"pros\", \"prosper\", \"prosperity\", \"prosperous\", \n",
    "    \"prospros\", \"protect\", \"protection\", \"protective\", \"proud\", \"proven\", \"proves\", \"providence\", \n",
    "    \"proving\", \"prowess\", \"prudence\", \"prudent\", \"prudently\", \"punctual\", \"pure\", \"purify\", \"purposeful\", \n",
    "    \"quaint\", \"qualified\", \"qualify\", \"quicker\", \"quiet\", \"quieter\", \"radiance\", \"radiant\", \"rapid\", \n",
    "    \"rapport\", \"rapt\", \"rapture\", \"raptureous\", \"raptureously\", \"rapturous\", \"rapturously\", \"rational\", \n",
    "    \"razor-sharp\", \"reachable\", \"readable\", \"readily\", \"ready\", \"reaffirm\", \"reaffirmation\", \"realistic\", \n",
    "    \"realizable\", \"reasonable\", \"reasonably\", \"reasoned\", \"reassurance\", \"reassure\", \"receptive\", \n",
    "    \"reclaim\", \"recommend\", \"recommendation\", \"recommendations\", \"recommended\", \"reconcile\", \n",
    "    \"record-setting\", \"recover\", \"recovery\", \"rectification\", \"rectify\", \"rectifying\", \"redeem\", \n",
    "    \"redeeming\", \"redemption\", \"refine\", \"refined\", \"refinement\", \"reform\", \"reformed\", \"reforming\", \n",
    "    \"reforms\", \"refresh\", \"refreshed\", \"refreshing\", \"refund\", \"refunded\", \"regal\", \"regally\", \n",
    "    \"regard\", \"rejoice\", \"rejoicing\", \"rejoicingly\", \"rejuvenate\", \"rejuvenated\", \"rejuvenating\", \n",
    "    \"relaxed\", \"relent\", \"reliable\", \"reliably\", \"relief\", \"relish\", \"remarkable\", \"remarkably\", \n",
    "    \"remedy\", \"remission\", \"remunerate\", \"renaissance\", \"renewed\", \"renown\", \"renowned\", \"replaceable\", \n",
    "    \"reputable\", \"rescue\", \"rescued\", \"resilient\", \"resolute\", \"resound\", \"resounding\", \"resourceful\", \n",
    "    \"resourcefulness\", \"respect\", \"respectable\", \"respectful\", \"respectfully\", \"respite\", \"resplendent\", \n",
    "    \"responsibly\", \"responsive\", \"restful\", \"restored\", \"restructure\", \"restructured\", \"restructuring\", \n",
    "    \"retractable\", \"revel\", \"revelation\", \"revere\", \"revered\", \"reverence\", \"reverent\", \"reverently\", \n",
    "    \"revitalize\", \"revival\", \"revive\", \"revives\", \"revolutionize\", \"revolutionized\", \"revolutionizes\", \n",
    "    \"reward\", \"rewarding\", \"rewardingly\", \"rich\", \"richer\", \"richly\", \"richness\", \"right\", \"righten\", \n",
    "    \"righteous\", \"righteously\", \"righteousness\", \"rightful\", \"rightfully\", \"rightly\", \"rightness\", \n",
    "    \"risk-free\", \"robust\", \"rock-star\", \"rock-stars\", \"rockstar\", \"rockstars\", \"romantic\", \"romantically\", \n",
    "    \"romanticize\", \"roomier\", \"roomy\", \"rosy\", \"safe\", \"safely\", \"sagacity\", \"sagely\", \"saint\", \"saintliness\", \n",
    "    \"saintly\", \"salient\", \"salvation\", \"sane\", \"sanity\", \"satisfaction\", \"satisfactorily\", \"satisfactory\", \n",
    "    \"satisfied\", \"satisfies\", \"satisfy\", \"satisfying\", \"satisified\", \"saver\", \"savings\", \"savior\", \"savvy\", \n",
    "    \"scenic\", \"seamless\", \"seasoned\", \"secure\", \"securely\", \"selective\", \"self-determination\", \n",
    "    \"self-respect\", \"self-satisfaction\", \"self-sufficiency\", \"self-sufficient\", \"sensation\", \n",
    "    \"sensational\", \"sensationally\", \"sensations\", \"sensible\", \"sensibly\", \"sensitive\", \n",
    "    \"serene\", \"serenity\", \"sexy\", \"sharp\", \"sharper\", \"sharpest\", \"shimmering\", \"shimmeringly\", \n",
    "    \"shine\", \"shiny\", \"significant\", \"silent\", \"simpler\", \"simplest\", \"simplified\", \n",
    "    \"simplifies\", \"simplify\", \"simplifying\", \"sincere\", \"sincerely\", \"sincerity\", \"skill\", \n",
    "    \"skilled\", \"skillful\", \"skillfully\", \"sleek\", \"slick\", \"smart\", \"smarter\", \"smartest\", \n",
    "    \"smartly\", \"smile\", \"smiles\", \"smiling\", \"smilingly\", \"smitten\", \"smooth\", \"smoother\", \n",
    "    \"smoothes\", \"smoothest\", \"smoothly\", \"snappy\", \"snazzy\", \"sociable\", \"soft\", \"softer\", \n",
    "    \"solace\", \"solicitous\", \"solicitously\", \"solid\", \"solidarity\", \"soothe\", \"soothingly\", \n",
    "    \"sophisticated\", \"soulful\", \"soundly\", \"soundness\", \"spacious\", \"sparkle\", \"sparkling\", \n",
    "    \"spectacular\", \"spectacularly\", \"speedily\", \"speedy\", \"spellbind\", \"spellbinding\", \n",
    "    \"spellbindingly\", \"spellbound\", \"spirited\", \"spiritual\", \"splendid\", \"splendidly\", \n",
    "    \"splendor\", \"spontaneous\", \"sporty\", \"spotless\", \"sprightly\", \"stability\", \"stabilize\", \n",
    "    \"stable\", \"stainless\", \"standout\", \"state-of-the-art\", \"stately\", \"statuesque\", \n",
    "    \"staunch\", \"staunchly\", \"staunchness\", \"steadfast\", \"steadfastly\", \"steadfastness\", \n",
    "    \"steadiest\", \"steadiness\", \"steady\", \"stellar\", \"stellarly\", \"stimulate\", \"stimulates\", \n",
    "    \"stimulating\", \"stimulative\", \"stirringly\", \"straighten\", \"straightforward\", \"streamlined\", \n",
    "    \"striking\", \"strikingly\", \"striving\", \"strong\", \"stronger\", \"strongest\", \"stunned\", \"stunning\", \n",
    "    \"stunningly\", \"stupendous\", \"stupendously\", \"sturdier\", \"sturdy\", \"stylish\", \"stylishly\", \n",
    "    \"stylized\", \"suave\", \"suavely\", \"sublime\", \"subsidize\", \"subsidized\", \"subsidizes\", \n",
    "    \"subsidizing\", \"substantive\", \"succeed\", \"succeeded\", \"succeeding\", \"succeeds\", \"succes\", \n",
    "    \"success\", \"successes\", \"successful\", \"successfully\", \"suffice\", \"sufficed\", \"suffices\", \n",
    "    \"sufficient\", \"sufficiently\", \"suitable\", \"sumptuous\", \"sumptuously\", \"sumptuousness\", \n",
    "    \"super\", \"superb\", \"superbly\", \"superior\", \"superiority\", \"supple\", \"support\", \"supported\", \n",
    "    \"supporter\", \"supporting\", \"supportive\", \"supports\", \"supremacy\", \"supreme\", \"supremely\", \n",
    "    \"supurb\", \"supurbly\", \"surmount\", \"surpass\", \"surreal\", \"survival\", \"survivor\", \"sustainability\", \n",
    "    \"sustainable\", \"swank\", \"swankier\", \"swankiest\", \"swanky\", \"sweeping\", \"sweet\", \"sweeten\", \n",
    "    \"sweetheart\", \"sweetly\", \"sweetness\", \"swift\", \"swiftness\", \"talent\", \"talented\", \"talents\", \n",
    "    \"tantalize\", \"tantalizing\", \"tantalizingly\", \"tempt\", \"tempting\", \"temptingly\", \"tenacious\", \n",
    "    \"tenaciously\", \"tenacity\", \"tender\", \"tenderly\", \"terrific\", \"terrifically\", \"thank\", \"thankful\", \n",
    "    \"thinner\", \"thoughtful\", \"thoughtfully\", \"thoughtfulness\", \"thrift\", \"thrifty\", \"thrill\", \n",
    "    \"thrilled\", \"thrilling\", \"thrillingly\", \"thrills\", \"thrive\", \"thriving\", \"thumb-up\", \"thumbs-up\", \n",
    "    \"tickle\", \"tidy\", \"time-honored\", \"timely\", \"tingle\", \"titillate\", \"titillating\", \"titillatingly\", \n",
    "    \"toast\", \"togetherness\", \"tolerable\", \"toll-free\", \"top\", \"top-notch\", \"top-quality\", \"topnotch\", \n",
    "    \"tops\", \"tough\", \"tougher\", \"toughest\", \"tranquil\", \"tranquility\", \"transparent\", \"treasure\", \n",
    "    \"tremendously\", \"trendy\", \"triumph\", \"triumphal\", \"triumphant\", \"triumphantly\", \"trivially\", \n",
    "    \"trophy\", \"trouble-free\", \"trump\", \"trumpet\", \"trust\", \"trusted\", \"trusting\", \"trustingly\", \"trustworthiness\", \n",
    "    \"trustworthy\", \"trusty\", \"truthful\", \"truthfully\", \"truthfulness\", \"twinkly\", \"ultra-crisp\", \n",
    "    \"unabashed\", \"unabashedly\", \"unaffected\", \"unassailable\", \"unbeatable\", \"unbiased\", \"unbound\", \n",
    "    \"uncomplicated\", \"unconditional\", \"undamaged\", \"undaunted\", \"understandable\", \"undisputable\", \n",
    "    \"undisputably\", \"undisputed\", \"unencumbered\", \"unequivocal\", \"unequivocally\", \"unfazed\", \"unfettered\", \n",
    "    \"unforgettable\", \"unity\", \"unlimited\", \"unmatched\", \"unparalleled\", \"unquestionable\", \"unquestionably\", \n",
    "    \"unreal\", \"unrestricted\", \"unrivaled\", \"unselfish\", \"unwavering\", \"upbeat\", \"upgradable\", \"upgradeable\", \n",
    "    \"upgraded\", \"upheld\", \"uphold\", \"uplift\", \"uplifting\", \"upliftingly\", \"upliftment\", \"upscale\", \"usable\", \n",
    "    \"useful\", \"user-friendly\", \"user-replaceable\", \"valiant\", \"valiantly\", \"valor\", \"valuable\", \"variety\", \n",
    "    \"venerate\", \"verifiable\", \"veritable\", \"versatile\", \"versatility\", \"vibrant\", \"vibrantly\", \"victorious\", \n",
    "    \"victory\", \"viewable\", \"vigilance\", \"vigilant\", \"virtue\", \"virtuous\", \"virtuously\", \"visionary\", \n",
    "    \"vivacious\", \"vivid\", \"voluntarily\", \"voluntary\", \"vulnerability\", \"vulnerable\", \"warm\", \"warmer\", \n",
    "    \"warmhearted\", \"warmly\", \"warmth\", \"wealthy\", \"welcome\", \"well\", \"well-backlit\", \"well-balanced\", \n",
    "    \"well-behaved\", \"well-being\", \"well-bred\", \"well-connected\", \"well-educated\", \"well-established\", \n",
    "    \"well-informed\", \"well-intentioned\", \"well-known\", \"well-made\", \"well-managed\", \"well-mannered\", \n",
    "    \"well-positioned\", \"well-publicized\", \"well-regarded\", \"well-rounded\", \"well-run\", \"well-wishers\", \n",
    "    \"wellbeing\", \"whoa\", \"wholeheartedly\", \"wholesome\", \"whooa\", \"whoooa\", \"wieldy\", \"willing\", \"willingly\", \n",
    "    \"willingness\", \"win\", \"windfall\", \"winnable\", \"winner\", \"winners\", \"winning\", \"wins\", \"wisdom\", \"wise\", \n",
    "    \"wisely\", \"witty\", \"won\", \"wonder\", \"wonderful\", \"wonderfully\", \"wonderous\", \"wonderously\", \"wonders\", \n",
    "    \"wondrous\", \"woo\", \"work\", \"workable\", \"worked\", \"works\", \"world-famous\", \"worth\", \"worth-while\", \n",
    "    \"worthiness\", \"worthwhile\", \"worthy\", \"wow\", \"wowed\", \"wowing\", \"wows\", \"yay\", \"youthful\", \"zeal\", \n",
    "    \"zenith\", \"zest\", \"zippy\", \"glamorous\", \"helpful\", \"light-hearted\", \"lovely\", \"loyal\", \"magic\", \n",
    "    \"miracle\", \"miraculous\", \"nifty\", \"nice\", \"originality\", \"paradise\", \"phenomenal\", \"pleasant\", \n",
    "    \"pleasantly\", \"pleased\", \"pleasing\", \"positive\", \"praise\", \"praiseworthy\", \"precious\", \"premium\", \n",
    "    \"remarkable\", \"satisfied\", \"satisfaction\", \"satisfy\", \"smart\", \"smooth\", \"splendid\", \"stellar\", \n",
    "    \"superb\", \"superior\", \"terrific\", \"thank\", \"thorough\", \"thrilled\", \"top\", \"top-notch\", \"treasure\", \n",
    "    \"triumph\", \"trust\", \"unbeatable\", \"upbeat\", \"vibrant\", \"victory\", \"well\", \"willing\", \"win\", \"winner\", \n",
    "    \"winning\", \"wow\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b58cf0a",
   "metadata": {},
   "source": [
    "### Negative Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab8a3e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample Negative Dictionary\n",
    "negative_dictionary = [ \"abandon\", \"aberration\", \"abhor\", \"abject\", \"abnormal\", \"abolish\", \"abominable\", \n",
    "    \"abomination\", \"abrade\", \"abrasive\", \"abrupt\", \"abscond\", \"absence\", \"absurd\", \n",
    "    \"absurdity\", \"abuse\", \"abysmal\", \"abyss\", \"accidental\", \"accursed\", \"accusation\", \n",
    "    \"accuse\", \"acerbic\", \"achy\", \"acrid\", \"adamant\", \"addict\", \"admonish\", \"adulterate\", \n",
    "    \"adversary\", \"adversity\", \"afflict\", \"afraid\", \"aggravate\", \"aggression\", \"aggressive\", \n",
    "    \"agonize\", \"agony\", \"ail\", \"ailment\", \"alarm\", \"alienate\", \"allergic\", \"aloof\", \n",
    "    \"amiss\", \"amputate\", \"anger\", \"angry\", \"anguish\", \"annihilate\", \"annoy\", \"annoyance\", \n",
    "    \"anomalous\", \"antagonistic\", \"antagonize\", \"anxiety\", \"anxious\", \"apathetic\", \n",
    "    \"apathy\", \"appalling\", \"apprehension\", \"apprehensive\", \"arbitrary\", \"archaic\", \n",
    "    \"argumentative\", \"arrogance\", \"arrogant\", \"ashamed\", \"asinine\", \"aspersion\", \n",
    "    \"assassin\", \"assault\", \"astray\", \"atrocious\", \"atrocity\", \"attack\", \"audacious\", \n",
    "    \"austere\", \"authenticity\", \"avoid\", \"awful\", \"awkward\", \"backwards\", \"bad\", \"bane\", \n",
    "    \"barbaric\", \"barbarous\", \"barren\", \"baseless\", \"bashful\", \"battered\", \"battle\", \n",
    "    \"belligerent\", \"bemoan\", \"beneath\", \"berserk\", \"betray\", \"betrayal\", \"bewildered\", \n",
    "    \"bias\", \"bicker\", \"bitter\", \"bizarre\", \"blackmail\", \"blah\", \"blame\", \"blasted\", \n",
    "    \"blatant\", \"bleak\", \"bleed\", \"blemish\", \"blindside\", \"blister\", \"block\", \"blockade\", \n",
    "    \"blunt\", \"blur\", \"blurt\", \"boastful\", \"bombard\", \"bombastic\", \"bondage\", \"bother\", \n",
    "    \"bothersome\", \"brash\", \"bravado\", \"breach\", \"break\", \"breakdown\", \"broken\", \n",
    "    \"brutal\", \"brutality\", \"brute\", \"burden\", \"burn\", \"burning\", \"busy\", \"butt\", \n",
    "    \"bypass\", \"calamity\", \"callous\", \"calumny\", \"cancer\", \"candid\", \"cannibal\", \n",
    "    \"capricious\", \"careless\", \"cataclysm\", \"catastrophe\", \"caustic\", \"cave\", \n",
    "    \"cease\", \"cessation\", \"chafe\", \"challenge\", \"chaos\", \"chaotic\", \"charge\", \n",
    "    \"charlatan\", \"cheat\", \"cheater\", \"cheesy\", \"chide\", \"chilling\", \"choke\", \n",
    "    \"chronic\", \"clash\", \"clumsy\", \"coarse\", \"collapse\", \"collide\", \"collision\", \n",
    "    \"complain\", \"complicate\", \"compulsion\", \"conceal\", \"conceited\", \"concern\", \n",
    "    \"confine\", \"conflict\", \"confound\", \"confusion\", \"congested\", \"conquer\", \n",
    "    \"conspiracy\", \"contagion\", \"contempt\", \"contemptible\", \"contend\", \n",
    "    \"contentious\", \"contort\", \"contradict\", \"contradiction\", \"contrary\", \n",
    "    \"contravene\", \"contrite\", \"controversial\", \"conundrum\", \"convict\", \n",
    "    \"conviction\", \"corrosive\", \"corrupt\", \"corruption\", \"costly\", \n",
    "    \"counterfeit\", \"counterproductive\", \"coward\", \"crabby\", \"crack\", \n",
    "    \"cramped\", \"cranky\", \"crap\", \"crash\", \"craven\", \"craze\", \"crazy\", \n",
    "    \"creep\", \"cripple\", \"crisis\", \"critic\", \"critical\", \"criticism\", \n",
    "    \"criticize\", \"crooked\", \"crude\", \"cruel\", \"cruelty\", \"crumble\", \n",
    "    \"crummy\", \"crush\", \"cryptic\", \"culpable\", \"cumbersome\", \"curse\", \n",
    "    \"cursed\", \"cynical\", \"damage\", \"damaging\", \"dampen\", \"danger\", \n",
    "    \"dangerous\", \"dark\", \"dastardly\", \"deadlock\", \"deadly\", \"deafening\", \n",
    "    \"death\", \"debase\", \"debatable\", \"deceit\", \"deceitful\", \"deceive\", \n",
    "    \"deception\", \"decimate\", \"decay\", \"deceptive\", \"decline\", \"defame\", \n",
    "    \"defect\", \"defective\", \"defend\", \"defender\", \"defensive\", \"defer\", \n",
    "    \"defiance\", \"defiant\", \"deficient\", \"defile\", \"defraud\", \"defunct\", \n",
    "    \"degenerate\", \"degradation\", \"degrade\", \"dejected\", \"delay\", \"deliberate\", \n",
    "    \"delusion\", \"delusional\", \"demanding\", \"demean\", \"demented\", \"demolish\", \n",
    "    \"demonic\", \"demonize\", \"denial\", \"denounce\", \"dense\", \"denunciation\", \n",
    "    \"deny\", \"deplete\", \"deplorable\", \"deplorably\", \"depraved\", \"depress\", \n",
    "    \"depressed\", \"depressing\", \"deprivation\", \"deride\", \"derision\", \n",
    "    \"derogatory\", \"desert\", \"desertion\", \"desolate\", \"despair\", \"desperate\", \n",
    "    \"desperation\", \"despise\", \"despondent\", \"destroy\", \"destruction\", \n",
    "    \"destructive\", \"detach\", \"detachment\", \"deter\", \"detest\", \"detestable\", \n",
    "    \"detour\", \"detract\", \"detriment\", \"devastate\", \"devastation\", \"deviate\", \n",
    "    \"devil\", \"devilish\", \"devious\", \"devour\", \"diabolic\", \"diabolical\", \n",
    "    \"dialect\", \"dictator\", \"difficult\", \"diffidence\", \"diminish\", \"dirt\", \n",
    "    \"dirty\", \"disable\", \"disadvantage\", \"disagree\", \"disagreeable\", \n",
    "    \"disappear\", \"disappointment\", \"disapprove\", \"disarm\", \"disaster\", \n",
    "    \"disastrous\", \"disavow\", \"disbelief\", \"discard\", \"discern\", \"discomfort\", \n",
    "    \"discompose\", \"disconcert\", \"discontent\", \"discontented\", \"discord\", \n",
    "    \"discourage\", \"discouragement\", \"discouraging\", \"discredit\", \"discreet\", \n",
    "    \"discrepancy\", \"disdain\", \"disdainful\", \"disease\", \"disfavor\", \"disgust\", \n",
    "    \"disgusting\", \"dishonest\", \"dishonor\", \"disillusion\", \"disinclined\", \n",
    "    \"disjointed\", \"dislike\", \"disloyal\", \"dismal\", \"dismay\", \"dismiss\", \n",
    "    \"disobey\", \"disorder\", \"disorganized\", \"disparage\", \"disparity\", \n",
    "    \"dispassionate\", \"displeased\", \"displeasure\", \"disposable\", \"disposal\", \n",
    "    \"disproportionate\", \"disprove\", \"dispute\", \"disquiet\", \"disregard\", \n",
    "    \"disrespect\", \"disrespectful\", \"disrupt\", \"disruption\", \"dissatisfaction\", \n",
    "    \"dissatisfied\", \"dissent\", \"disservice\", \"dissimilar\", \"dissipate\", \n",
    "    \"dissolve\", \"distant\", \"distaste\", \"distasteful\", \"distort\", \"distortion\", \n",
    "    \"distract\", \"distress\", \"distressing\", \"distrust\", \"disturb\", \"disturbed\", \n",
    "    \"divergent\", \"divide\", \"divisive\", \"dizzy\", \"dodgy\", \"dogged\", \"domineer\", \n",
    "    \"domineering\", \"doubt\", \"doubtful\", \"doubtfully\", \"down\", \"downcast\", \n",
    "    \"downfall\", \"downgrade\", \"downhearted\", \"downhill\", \"downside\", \"downturn\", \n",
    "    \"drab\", \"drag\", \"drain\", \"dread\", \"dreadful\", \"dreary\", \"drench\", \"dripping\", \n",
    "    \"drone\", \"droop\", \"drop\", \"drought\", \"drown\", \"drunk\", \"dry\", \"dubious\", \n",
    "    \"dud\", \"dull\", \"dumb\", \"dump\", \"dunce\", \"dupe\", \"dust\", \"dusty\", \"dwindle\", \n",
    "    \"dying\", \"earsplitting\", \"eccentric\", \"edgy\", \"egotistic\", \"egregious\", \n",
    "    \"eject\", \"elusive\", \"embarrass\", \"embarrassing\", \"embitter\", \"embittered\", \n",
    "    \"embrace\", \"embroil\", \"emphatic\", \"empty\", \"encroach\", \"endanger\", \"enemies\", \n",
    "    \"enemy\", \"enrage\", \"enraged\", \"enslave\", \"entangle\", \"entrap\", \"envious\", \n",
    "    \"erratic\", \"erroneous\", \"error\", \"eruption\", \"escape\", \"evade\", \"evict\", \n",
    "    \"evil\", \"exaggerate\", \"exasperate\", \"excruciating\", \"excuse\", \"exile\", \n",
    "    \"exorbitant\", \"expel\", \"expensive\", \"expire\", \"explode\", \"exploit\", \"expose\", \n",
    "    \"expulsion\", \"extinct\", \"extinguish\", \"extortion\", \"extraneous\", \"extravagant\", \n",
    "    \"exude\", \"exult\", \"eye-sore\", \"fail\", \"failure\", \"fake\", \"fall\", \"fallacy\", \n",
    "    \"fallen\", \"false\", \"falter\", \"fatal\", \"fatigue\", \"fault\", \"faulty\", \"fear\", \n",
    "    \"fearful\", \"feeble\", \"feeble-minded\", \"feign\", \"fell\", \"fiasco\", \"fickle\", \n",
    "    \"fiction\", \"fidget\", \"fiend\", \"filthy\", \"finicky\", \"fissure\", \"flag\", \"flagrant\", \n",
    "    \"flake\", \"flaky\", \"flaw\", \"flawed\", \"flee\", \"fleeting\", \"flimsy\", \"flirt\", \"flop\", \n",
    "    \"flout\", \"fluster\", \"foe\", \"fool\", \"foolish\", \"forbid\", \"forbidding\", \"force\", \n",
    "    \"forceful\", \"foreboding\", \"forgetful\", \"forgettable\", \"forsake\", \"foul\", \"fragmented\", \n",
    "    \"frantic\", \"fraud\", \"fraudulent\", \"freak\", \"freakish\", \"freeze\", \"fret\", \"friction\", \n",
    "    \"frivolous\", \"frown\", \"frustrate\", \"frustrating\", \"frustration\", \"fuck\", \"fudge\", \n",
    "    \"fugitive\", \"full\", \"fumble\", \"fume\", \"fundamental\", \"funeral\", \"funky\", \"funny\", \n",
    "    \"furious\", \"futility\", \"fuzzy\", \"gag\", \"gaffe\", \"gainsay\", \"gall\", \"garbage\", \n",
    "    \"gaudy\", \"gawk\", \"geeky\", \"generic\", \"ghastly\", \"ghostly\", \"gibberish\", \"gibe\", \n",
    "    \"giddy\", \"gimmick\", \"give-up\", \"glare\", \"glitch\", \"glower\", \"glum\", \"gnaw\", \"goofy\", \n",
    "    \"grave\", \"greed\", \"greedy\", \"grief\", \"grieve\", \"grievous\", \"grim\", \"grime\", \"grind\", \n",
    "    \"gripe\", \"gross\", \"grotesque\", \"grouch\", \"grouchy\", \"groundless\", \"growl\", \"grudge\", \n",
    "    \"gruesome\", \"grumble\", \"grumpy\", \"guilt\", \"guilty\", \"gullible\", \"gulp\", \"gutless\", \n",
    "    \"hack\", \"haggard\", \"haggle\", \"halt\", \"hamper\", \"hamstring\", \"handicap\", \"hang\", \n",
    "    \"haphazard\", \"harangue\", \"harass\", \"harassment\", \"harbinger\", \"harsh\", \"hassle\", \n",
    "    \"haste\", \"hasty\", \"hateful\", \"hate\", \"haughty\", \"haunt\", \"headache\", \"heartache\", \n",
    "    \"heartbreak\", \"heartless\", \"heat\", \"heinous\", \"hell\", \"hideous\", \"hideousness\", \n",
    "    \"hinder\", \"hindrance\", \"hoard\", \"hoax\", \"hobble\", \"hog\", \"hollow\", \"hopeless\", \n",
    "    \"horde\", \"horrible\", \"horrid\", \"horrific\", \"hostile\", \"hothead\", \"hubris\", \n",
    "    \"huckster\", \"hugely\", \"humble\", \"humiliate\", \"humiliation\", \"hurt\", \"hurtful\", \n",
    "    \"hustle\", \"hysteria\", \"hysterical\", \"icky\", \"idiocy\", \"idiot\", \"idiotic\", \"idle\", \n",
    "    \"ignoble\", \"ignominious\", \"ignorant\", \"ignore\", \"ill\", \"illegal\", \"illegitimate\", \n",
    "    \"illiterate\", \"illness\", \"illogical\", \"illusive\", \"illusory\", \"immaterial\", \n",
    "    \"immature\", \"imminence\", \"imminent\", \"immoral\", \"impair\", \"impairment\", \"impasse\", \n",
    "    \"impatient\", \"impeach\", \"impede\", \"impediment\", \"impending\", \"imperfect\", \"imperil\", \n",
    "    \"impersonal\", \"impetuous\", \"implicate\", \"implication\", \"implode\", \"implore\", \"imply\", \n",
    "    \"importunate\", \"importune\", \"impose\", \"imposition\", \"impossible\", \"impotent\", \n",
    "    \"impractical\", \"imprecise\", \"imprison\", \"imprisonment\", \"improbability\", \n",
    "    \"improbable\", \"improper\", \"improve\", \"improvement\", \"imprudent\", \"impudent\", \n",
    "    \"impugn\", \"impulse\", \"impulsive\", \"impunity\", \"impure\", \"inability\", \"inaccurate\", \n",
    "    \"inaction\", \"inactive\", \"inadequate\", \"inappropriate\", \"inarticulate\", \n",
    "    \"inattentive\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d91e30ec",
   "metadata": {},
   "source": [
    "### Positive Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e24a9aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate Positive Score\n",
    "def calculate_positive_score(title, positive_dictionary):\n",
    "    words = word_tokenize(title.lower())\n",
    "    positive_score = sum(1 for word in words if word in positive_dictionary)\n",
    "    return positive_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee2a8c9",
   "metadata": {},
   "source": [
    "* Tokenize the Title:\n",
    "\n",
    "word_tokenize(title.lower()): Converts the title to lowercase and tokenizes it into individual words.\n",
    "\n",
    "* Calculate Positive Score:\n",
    "\n",
    "sum(1 for word in words if word in positive_dictionary): Iterates through the tokenized words and counts how many of those words are present in the positive_dictionary.\n",
    "For each word in the tokenized list that matches a word in the positive dictionary, it adds 1 to the positive_score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e2bc97d",
   "metadata": {},
   "source": [
    "### Negative Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "55ffd408",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate Negative Score\n",
    "def calculate_negative_score(title, negative_dictionary):\n",
    "    words = word_tokenize(title.lower())\n",
    "    negative_score = sum(1 for word in words if word in negative_dictionary)\n",
    "    return negative_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e952953",
   "metadata": {},
   "source": [
    "* Tokenize the Title:\n",
    "\n",
    "word_tokenize(title.lower()): Converts the title to lowercase and tokenizes it into individual words.\n",
    "\n",
    "* Calculate Negative Score:\n",
    "\n",
    "sum(1 for word in words if word in negative_dictionary): Iterates through the tokenized words and counts how many of those words are present in the negative_dictionary.\n",
    "For each word in the tokenized list that matches a word in the negative dictionary, it adds 1 to the negative_score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c11d2e8",
   "metadata": {},
   "source": [
    "### Polarity Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f1858836",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate Polarity Score\n",
    "def calculate_polarity_score(positive_score, negative_score):\n",
    "    if positive_score == 0 and negative_score == 0:\n",
    "        return 0\n",
    "    return (positive_score - negative_score) / ((positive_score + negative_score) + 0.000001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "016281f4",
   "metadata": {},
   "source": [
    "* Check for Zero Division:\n",
    "\n",
    "if positive_score == 0 and negative_score == 0:: Checks if both positive_score and negative_score are zero. If so, returns a polarity score of 0 to avoid division by zero errors.\n",
    "\n",
    "* Calculate Polarity Score:\n",
    "\n",
    "(positive_score - negative_score): Computes the difference between positive_score and negative_score.\n",
    "((positive_score + negative_score) + 0.000001): Normalizes the difference by adding a small value (0.000001) to the sum of positive_score and negative_score to prevent division by zero.\n",
    "Returns the calculated polarity score, which ranges from -1 (strongly negative) to 1 (strongly positive)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e39468d9",
   "metadata": {},
   "source": [
    "### Subjectivity Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b7500def",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate Subjectivity Score\n",
    "def calculate_subjectivity_score(positive_score, negative_score, total_words):\n",
    "    if total_words == 0:\n",
    "        return 0\n",
    "    return (positive_score + negative_score) / (total_words + 0.000001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ffb36d",
   "metadata": {},
   "source": [
    "* Check for Zero Division:\n",
    "\n",
    "if total_words == 0:: Checks if total_words is zero. If so, returns a subjectivity score of 0 to avoid division by zero errors.\n",
    "\n",
    "* Calculate Subjectivity Score:\n",
    "\n",
    "(positive_score + negative_score): Computes the sum of positive_score and negative_score.\n",
    "(total_words + 0.000001): Normalizes the sum by adding a small value (0.000001) to total_words to prevent division by zero.\n",
    "Returns the calculated subjectivity score, which represents the ratio of positive and negative words relative to the total number of words in the text."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34575bd3",
   "metadata": {},
   "source": [
    "### Average Sentance Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ed39d74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate Average Sentence Length\n",
    "def calculate_avg_sentence_length(title):\n",
    "    sentences = title.split('.')\n",
    "    total_sentences = len(sentences)\n",
    "    total_words = len(word_tokenize(title))\n",
    "    if total_sentences == 0:\n",
    "        return 0\n",
    "    return total_words / total_sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6769e39",
   "metadata": {},
   "source": [
    "* Split Text into Sentences:\n",
    "\n",
    "sentences = title.split('.'): Splits the title into sentences based on periods ('.').\n",
    "This assumes sentences end with periods and may not handle abbreviations or other punctuation correctly.\n",
    "\n",
    "* Count Sentences and Words:\n",
    "\n",
    "total_sentences = len(sentences): Counts the total number of sentences obtained from splitting the text.\n",
    "total_words = len(word_tokenize(title)): Tokenizes the entire title into words and counts the total number of words.\n",
    "\n",
    "* Check for Zero Division:\n",
    "\n",
    "if total_sentences == 0:: Checks if total_sentences is zero. If so, returns an average sentence length of 0 to avoid division by zero errors.\n",
    "\n",
    "* Calculate Average Sentence Length:\n",
    "\n",
    "Returns the ratio of total_words to total_sentences, which gives the average number of words per sentence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19506e01",
   "metadata": {},
   "source": [
    "### Syllable Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dffc2274",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to count syllables in a word\n",
    "def calculate_syllable_count(word):\n",
    "    d = cmudict.dict()\n",
    "    if word.lower() in d:\n",
    "        return [len(list(y for y in x if y[-1].isdigit())) for x in d[word.lower()]][0]\n",
    "    else:\n",
    "        vowels = \"aeiou\"\n",
    "        count = 0\n",
    "        word = word.lower().strip(\".:;?!\")\n",
    "        if len(word) == 0:\n",
    "            return 0\n",
    "        if word[0] in vowels:\n",
    "            count += 1\n",
    "        for index in range(1, len(word)):\n",
    "            if word[index] in vowels and word[index - 1] not in vowels:\n",
    "                count += 1\n",
    "        if word.endswith(\"e\"):\n",
    "            count -= 1\n",
    "        if word.endswith(\"le\"):\n",
    "            count += 1\n",
    "        if count == 0:\n",
    "            count += 1\n",
    "        return count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c7cd9b",
   "metadata": {},
   "source": [
    "* Check CMU Dictionary:\n",
    "\n",
    "d = cmudict.dict(): Loads the CMU dictionary, which is a pronunciation dictionary.\n",
    "\n",
    "* Lookup Word in Dictionary:\n",
    "\n",
    "if word.lower() in d: Checks if the lowercase version of word exists in the CMU dictionary.\n",
    "If found, retrieves the syllable count using list comprehensions and parsing of the dictionary entry.\n",
    "\n",
    "* Heuristic Syllable Counting:\n",
    "\n",
    "If the word is not found in the dictionary, it uses a heuristic approach to count syllables:\n",
    "\n",
    "Initializes a count variable.\n",
    "Strips common punctuation from the word.\n",
    "Checks if the word starts with a vowel and increments the count.\n",
    "Iterates through the word to count syllables based on vowel occurrences and non-vowel transitions.\n",
    "Adjusts the syllable count based on common English syllable patterns (e at the end reduces count, le at the end increases count).\n",
    "Ensures the minimum syllable count is 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad16ab6f",
   "metadata": {},
   "source": [
    "### Count of Words, Count of Complex Words and Percentage of Complex Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "996a7b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate Count of Words,Count of Complex Words and Percentage of Complex words\n",
    "def calculate_complex_word_count(title):\n",
    "    words = word_tokenize(title.lower())\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    punctuations = set(string.punctuation)\n",
    "    complex_word_count = 0\n",
    "    total_words = 0\n",
    "    \n",
    "    def syllable_count(word):\n",
    "        return sum([len(list(y for y in x if y[-1].isdigit())) for x in cmudict.dict().get(word.lower(), [])])\n",
    "    \n",
    "    for word in words:\n",
    "        if word not in stop_words and word not in punctuations:\n",
    "            total_words += 1\n",
    "            if syllable_count(word) > 2:\n",
    "                complex_word_count += 1\n",
    "    if total_words == 0:\n",
    "        return 0, 0, 0 \n",
    "    percentage_complex_words = (complex_word_count / total_words) * 100\n",
    "    return complex_word_count, percentage_complex_words, total_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c09f8cfb",
   "metadata": {},
   "source": [
    "* Tokenize and Preprocess Text:\n",
    "\n",
    "words = word_tokenize(title.lower()): Tokenizes the lowercase version of title into individual words.\n",
    "\n",
    "* Initialize Variables:\n",
    "\n",
    "stop_words = set(stopwords.words('english')): Retrieves a set of English stopwords (common words like 'the', 'is', etc.) using NLTK.\n",
    "punctuations = set(string.punctuation): Retrieves a set of punctuation marks.\n",
    "Initializes complex_word_count and total_words counters.\n",
    "\n",
    "* Define Syllable Count Function:\n",
    "\n",
    "syllable_count(word): Defines an inner function to count syllables using the CMU dictionary (cmudict). If a word is not found in the dictionary, it returns 0.\n",
    "\n",
    "* Iterate Through Words:\n",
    "\n",
    "Iterates through each word in words.\n",
    "Checks if the word is not a stopword and not a punctuation mark.\n",
    "Increments total_words for each valid word encountered.\n",
    "Checks if syllable_count(word) > 2 to determine if the word is complex (having more than 2 syllables). If true, increments complex_word_count.\n",
    "\n",
    "* Handle Edge Case:\n",
    "\n",
    "Checks if total_words is 0 to avoid division by zero. If true, returns 0 for all counts (complex_word_count, percentage_complex_words, total_words).\n",
    "\n",
    "* Calculate Percentage of Complex Words:\n",
    "\n",
    "Computes percentage_complex_words as (complex_word_count / total_words) * 100.\n",
    "\n",
    "* Return Results:\n",
    "\n",
    "Returns a tuple containing complex_word_count, percentage_complex_words, and total_words."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee52964",
   "metadata": {},
   "source": [
    "### Fog Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b6a5021c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate Fog Index\n",
    "def calculate_fog_index(avg_sentence_length, percentage_complex_words):\n",
    "    return 0.4 * (avg_sentence_length + percentage_complex_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee1ea64",
   "metadata": {},
   "source": [
    "* Compute Fog Index:\n",
    "\n",
    "Calculates the Fog Index using the formula 0.4 * (avg_sentence_length + percentage_complex_words).\n",
    "The Fog Index formula combines the average sentence length and the percentage of complex words to estimate the readability level of the text."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c481b6",
   "metadata": {},
   "source": [
    "### Average Word Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "49f2ea72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate Average Word Length\n",
    "def calculate_avg_word_length(title):\n",
    "    words = word_tokenize(title.lower())\n",
    "    total_words = len(words)\n",
    "    if total_words == 0:\n",
    "        return 0\n",
    "    total_length = sum(len(word) for word in words)\n",
    "    return total_length / total_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d690198",
   "metadata": {},
   "source": [
    "* Tokenize the Text:\n",
    "\n",
    "words = word_tokenize(title.lower()): Tokenizes the lowercase version of title into individual words.\n",
    "\n",
    "* Calculate Total Words:\n",
    "\n",
    "total_words = len(words): Counts the total number of words in the tokenized list words.\n",
    "\n",
    "* Check for Zero Division:\n",
    "\n",
    "if total_words == 0:: Checks if total_words is zero. If so, returns an average word length of 0 to avoid division by zero errors.\n",
    "\n",
    "* Calculate Total Length of Words:\n",
    "\n",
    "total_length = sum(len(word) for word in words): Computes the total length of all words by summing the length of each word in words.\n",
    "\n",
    "* Compute Average Word Length:\n",
    "\n",
    "Returns the average word length by dividing total_length by total_words."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c19d9da",
   "metadata": {},
   "source": [
    "### Personal Pronouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9db980d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to count personal pronouns\n",
    "def count_personal_pronouns(title):\n",
    "    words = word_tokenize(title.lower())\n",
    "    personal_pronouns = ['i', 'me', 'my', 'mine', 'myself', 'we', 'us', 'our', 'ours', 'ourselves',\n",
    "                    'you', 'your', 'yours', 'yourself', 'yourselves',\n",
    "                    'he', 'him', 'his', 'himself', 'she', 'her', 'hers', 'herself',\n",
    "                    'it', 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves']\n",
    "    return sum(1 for word in words if word in personal_pronouns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deff80cd",
   "metadata": {},
   "source": [
    "* Tokenize the Text:\n",
    "\n",
    "words = word_tokenize(title.lower()): Tokenizes the lowercase version of title into individual words.\n",
    "\n",
    "* Define Personal Pronouns List:\n",
    "\n",
    "personal_pronouns: Contains a predefined list of personal pronouns commonly used in English.\n",
    "\n",
    "* Count Personal Pronouns:\n",
    "\n",
    "Uses a generator expression within the sum() function to iterate through each word in words.\n",
    "Checks if each word exists in the personal_pronouns list.\n",
    "Increments the count for each word found in the list."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e97d4f",
   "metadata": {},
   "source": [
    "### Average Words Per Sentance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f79e7724",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_avg_words_per_sentence(title):\n",
    "    total_words = len(word_tokenize(title))\n",
    "    avg_sentence_length, total_sentences = calculate_avg_sentence_length(title)\n",
    "    if total_sentences == 0:\n",
    "        return 0\n",
    "    return total_words / total_sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "879d3ca0",
   "metadata": {},
   "source": [
    "* Tokenize Text:\n",
    "\n",
    "words = word_tokenize(title): Tokenizes the title into words using NLTK's word_tokenize function.\n",
    "\n",
    "* Count Words and Sentences:\n",
    "\n",
    "total_words = len(words): Counts the total number of words in the tokenized title.\n",
    "total_sentences = len(sent_tokenize(title)): Counts the total number of sentences in the title using NLTK's sent_tokenize function.\n",
    "\n",
    "* Check for Zero Division:\n",
    "\n",
    "if total_sentences == 0: Checks if total_sentences is zero to avoid division by zero error.\n",
    "\n",
    "* Calculate Average Words per Sentence:\n",
    "\n",
    "Returns the average number of words per sentence by dividing total_words by total_sentences."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ac0263",
   "metadata": {},
   "source": [
    "### Creating Lists to Store Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8fdd5885",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create lists to store the Datas\n",
    "titles_list = []\n",
    "positive_scores = []\n",
    "negative_scores = []\n",
    "polarity_scores = []\n",
    "subjectivity_scores = []\n",
    "avg_sentence_lengths = []\n",
    "percentage_complex_words_list = []\n",
    "fog_index_list = []\n",
    "complex_word_count_list = []\n",
    "total_words_list = []\n",
    "syllable_count_list = []\n",
    "personal_pronouns_list = []\n",
    "avg_word_length_list = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0beec250",
   "metadata": {},
   "source": [
    "### Iterating Through DataFrame and Processing Each URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e6079367",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching URL: https://insights.blackcoffer.com/dashboard-to-track-the-analytics-of-the-website-using-google-analytics-and-google-tag-manager/. Exception: 502 Server Error: Bad Gateway for url: https://insights.blackcoffer.com/dashboard-to-track-the-analytics-of-the-website-using-google-analytics-and-google-tag-manager/\n"
     ]
    }
   ],
   "source": [
    "# Iterate through the DataFrame and process each URL\n",
    "for index, row in df.iterrows():\n",
    "    title = extract_article_title(row['URL'])\n",
    "    \n",
    "    if title:\n",
    "        positive_score = calculate_positive_score(title, positive_dictionary)\n",
    "        negative_score = calculate_negative_score(title, negative_dictionary)\n",
    "        polarity_score = calculate_polarity_score(positive_score, negative_score)\n",
    "        total_words_count = len(word_tokenize(title))\n",
    "        subjectivity_score = calculate_subjectivity_score(positive_score, negative_score, total_words_count)\n",
    "        avg_sentence_length = calculate_avg_sentence_length(title)\n",
    "        complex_word_count, percentage_complex_words, total_words = calculate_complex_word_count(title)\n",
    "        fog_index = calculate_fog_index(avg_sentence_length, percentage_complex_words)\n",
    "        syllable_count = calculate_syllable_count(title)\n",
    "        personal_pronouns = count_personal_pronouns(title)\n",
    "        avg_word_length = calculate_avg_word_length(title)\n",
    "    else:\n",
    "        positive_score = negative_score = polarity_score = subjectivity_score = None\n",
    "        avg_sentence_length = percentage_complex_words = fog_index = 0\n",
    "        complex_word_count = total_words = syllable_count = personal_pronouns = avg_word_length = 0\n",
    "    \n",
    "    # Append values to respective lists\n",
    "    titles_list.append(title)\n",
    "    positive_scores.append(positive_score)\n",
    "    negative_scores.append(negative_score)\n",
    "    polarity_scores.append(polarity_score)\n",
    "    subjectivity_scores.append(subjectivity_score)\n",
    "    avg_sentence_lengths.append(avg_sentence_length)\n",
    "    percentage_complex_words_list.append(percentage_complex_words)\n",
    "    fog_index_list.append(fog_index)\n",
    "    complex_word_count_list.append(complex_word_count)\n",
    "    total_words_list.append(total_words)\n",
    "    syllable_count_list.append(syllable_count)\n",
    "    personal_pronouns_list.append(personal_pronouns)\n",
    "    avg_word_length_list.append(avg_word_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ea2a27",
   "metadata": {},
   "source": [
    "* DataFrame Iteration:\n",
    "\n",
    "for index, row in df.iterrows():: Iterates through each row (row) in the DataFrame (df). index represents the index of the row.\n",
    "\n",
    "* Extracting Article Title:\n",
    "\n",
    "title = extract_article_title(row['URL']): Calls the extract_article_title function to fetch and clean the title from the URL provided in the current row (row['URL']).\n",
    "\n",
    "Calculating Metrics:\n",
    "\n",
    "* Sentiment Analysis:\n",
    "\n",
    "positive_score, negative_score, polarity_score: Calculate positive and negative scores using predefined dictionaries (positive_dictionary, negative_dictionary), and then compute the polarity score based on these scores.\n",
    "\n",
    "* Text Complexity:\n",
    "\n",
    "total_words_count: Counts the total number of words in the title using len(word_tokenize(title)).\n",
    "subjectivity_score: Computes the subjectivity score based on positive score, negative score, and total words count.\n",
    "avg_sentence_length: Calculates the average sentence length in terms of words.\n",
    "complex_word_count, percentage_complex_words, total_words: Calculates the count of complex words, percentage of complex words, and total words count in the title.\n",
    "fog_index: Computes the Fog Index based on average sentence length and percentage of complex words.\n",
    "syllable_count: Counts the syllables in the title.\n",
    "personal_pronouns: Counts personal pronouns (like 'I', 'you', 'he', etc.) in the title.\n",
    "avg_word_length: Calculates the average word length in the title.\n",
    "\n",
    "* Handling Errors:\n",
    "\n",
    "If the title extraction fails (if not title:), default values (None or 0) are assigned to the metrics to avoid errors.\n",
    "\n",
    "* Storing Results:\n",
    "\n",
    "Appends all calculated metrics (title, positive_score, negative_score, polarity_score, etc.) to their respective lists (titles_list, positive_scores, negative_scores, etc.)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32729b45",
   "metadata": {},
   "source": [
    "### Adding Results to DataFrame and Saving to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6de117a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Article titles and scores extracted and saved successfully.\n"
     ]
    }
   ],
   "source": [
    "# Add the results to the DataFrame\n",
    "df['TITLE'] = titles_list\n",
    "df['POSITIVE SCORE'] = positive_scores\n",
    "df['NEGATIVE SCORE'] = negative_scores\n",
    "df['POLARITY SCORE'] = polarity_scores\n",
    "df['SUBJECTIVITY SCORE'] = subjectivity_scores\n",
    "df['AVG SENTENCE LENGTH'] = avg_sentence_lengths\n",
    "df['PERCENTAGE OF COMPLEX WORDS'] = percentage_complex_words_list\n",
    "df['FOG INDEX'] = fog_index_list\n",
    "df['COMPLEX WORD COUNT'] = complex_word_count_list\n",
    "df['WORD COUNT'] = total_words_list\n",
    "df['SYLLABLE PER WORD'] = syllable_count_list\n",
    "df['PERSONAL PRONOUNS'] = personal_pronouns_list\n",
    "df['AVG WORD LENGTH'] = avg_word_length_list\n",
    "\n",
    "# Save the DataFrame to a new Excel file\n",
    "output_file_path = 'C:/Users/abine/Desktop/Jupyter Notebook/BlackCoffer Project/Output.csv'\n",
    "df.to_csv(output_file_path, index=False)\n",
    "\n",
    "print(\"Article titles and scores extracted and saved successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "526c1ca4",
   "metadata": {},
   "source": [
    "* Adding Columns to DataFrame:\n",
    "\n",
    "Each list (titles_list, positive_scores, negative_scores, etc.) containing calculated metrics is assigned to a new column in the DataFrame (df). This step aligns each metric with its corresponding article title.\n",
    "\n",
    "* Output File Path:\n",
    "\n",
    "output_file_path: Specifies the path where the CSV file ('Output.csv') will be saved. Adjust this path according to your local file system structure.\n",
    "\n",
    "* Saving to CSV:\n",
    "\n",
    "df.to_csv(output_file_path, index=False): Saves the updated DataFrame to a CSV file without including the index column."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ffa0f75",
   "metadata": {},
   "source": [
    "### Ouput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1035615f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL_ID</th>\n",
       "      <th>URL</th>\n",
       "      <th>TITLE</th>\n",
       "      <th>POSITIVE SCORE</th>\n",
       "      <th>NEGATIVE SCORE</th>\n",
       "      <th>POLARITY SCORE</th>\n",
       "      <th>SUBJECTIVITY SCORE</th>\n",
       "      <th>AVG SENTENCE LENGTH</th>\n",
       "      <th>PERCENTAGE OF COMPLEX WORDS</th>\n",
       "      <th>FOG INDEX</th>\n",
       "      <th>COMPLEX WORD COUNT</th>\n",
       "      <th>WORD COUNT</th>\n",
       "      <th>SYLLABLE PER WORD</th>\n",
       "      <th>PERSONAL PRONOUNS</th>\n",
       "      <th>AVG WORD LENGTH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bctech2011</td>\n",
       "      <td>https://insights.blackcoffer.com/ml-and-ai-bas...</td>\n",
       "      <td>ML and AI-based insurance premium model to pre...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>16.0</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>30.400000</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>5.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bctech2012</td>\n",
       "      <td>https://insights.blackcoffer.com/streamlined-i...</td>\n",
       "      <td>Streamlined Integration: Interactive Brokers A...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>12.0</td>\n",
       "      <td>33.333333</td>\n",
       "      <td>18.133333</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>6.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bctech2013</td>\n",
       "      <td>https://insights.blackcoffer.com/efficient-dat...</td>\n",
       "      <td>Efficient Data Integration and User-Friendly I...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>14.0</td>\n",
       "      <td>81.818182</td>\n",
       "      <td>38.327273</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>7.642857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bctech2014</td>\n",
       "      <td>https://insights.blackcoffer.com/effective-man...</td>\n",
       "      <td>Effective Management of Social Media Data Extr...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>16.0</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>42.400000</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>6.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bctech2015</td>\n",
       "      <td>https://insights.blackcoffer.com/streamlined-t...</td>\n",
       "      <td>Streamlined Trading Operations Interface for M...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>13.0</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>29.200000</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>7.230769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>bctech2153</td>\n",
       "      <td>https://insights.blackcoffer.com/population-an...</td>\n",
       "      <td>Population and Community Survey of America</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>42.400000</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>6.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>bctech2154</td>\n",
       "      <td>https://insights.blackcoffer.com/google-lsa-ap...</td>\n",
       "      <td>Google LSA API Data Automation and Dashboarding</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.0</td>\n",
       "      <td>33.333333</td>\n",
       "      <td>16.133333</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>5.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>bctech2155</td>\n",
       "      <td>https://insights.blackcoffer.com/healthcare-da...</td>\n",
       "      <td>Healthcare Data Analysis</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>27.866667</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>7.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>bctech2156</td>\n",
       "      <td>https://insights.blackcoffer.com/budget-sales-...</td>\n",
       "      <td>Budget, Sales KPI Dashboard using Power BI</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.200000</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>4.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>bctech2157</td>\n",
       "      <td>https://insights.blackcoffer.com/amazon-buy-bo...</td>\n",
       "      <td>Amazon Buy Bot, an Automation AI tool to Auto-...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>42.857143</td>\n",
       "      <td>21.142857</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>4.700000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>147 rows Ã— 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         URL_ID                                                URL  \\\n",
       "0    bctech2011  https://insights.blackcoffer.com/ml-and-ai-bas...   \n",
       "1    bctech2012  https://insights.blackcoffer.com/streamlined-i...   \n",
       "2    bctech2013  https://insights.blackcoffer.com/efficient-dat...   \n",
       "3    bctech2014  https://insights.blackcoffer.com/effective-man...   \n",
       "4    bctech2015  https://insights.blackcoffer.com/streamlined-t...   \n",
       "..          ...                                                ...   \n",
       "142  bctech2153  https://insights.blackcoffer.com/population-an...   \n",
       "143  bctech2154  https://insights.blackcoffer.com/google-lsa-ap...   \n",
       "144  bctech2155  https://insights.blackcoffer.com/healthcare-da...   \n",
       "145  bctech2156  https://insights.blackcoffer.com/budget-sales-...   \n",
       "146  bctech2157  https://insights.blackcoffer.com/amazon-buy-bo...   \n",
       "\n",
       "                                                 TITLE  POSITIVE SCORE  \\\n",
       "0    ML and AI-based insurance premium model to pre...             2.0   \n",
       "1    Streamlined Integration: Interactive Brokers A...             1.0   \n",
       "2    Efficient Data Integration and User-Friendly I...             2.0   \n",
       "3    Effective Management of Social Media Data Extr...             1.0   \n",
       "4    Streamlined Trading Operations Interface for M...             2.0   \n",
       "..                                                 ...             ...   \n",
       "142         Population and Community Survey of America             0.0   \n",
       "143    Google LSA API Data Automation and Dashboarding             0.0   \n",
       "144                           Healthcare Data Analysis             0.0   \n",
       "145         Budget, Sales KPI Dashboard using Power BI             0.0   \n",
       "146  Amazon Buy Bot, an Automation AI tool to Auto-...             0.0   \n",
       "\n",
       "     NEGATIVE SCORE  POLARITY SCORE  SUBJECTIVITY SCORE  AVG SENTENCE LENGTH  \\\n",
       "0               0.0        1.000000            0.125000                 16.0   \n",
       "1               0.0        0.999999            0.083333                 12.0   \n",
       "2               0.0        1.000000            0.142857                 14.0   \n",
       "3               0.0        0.999999            0.062500                 16.0   \n",
       "4               0.0        1.000000            0.153846                 13.0   \n",
       "..              ...             ...                 ...                  ...   \n",
       "142             0.0        0.000000            0.000000                  6.0   \n",
       "143             0.0        0.000000            0.000000                  7.0   \n",
       "144             0.0        0.000000            0.000000                  3.0   \n",
       "145             0.0        0.000000            0.000000                  8.0   \n",
       "146             0.0        0.000000            0.000000                 10.0   \n",
       "\n",
       "     PERCENTAGE OF COMPLEX WORDS  FOG INDEX  COMPLEX WORD COUNT  WORD COUNT  \\\n",
       "0                      60.000000  30.400000                   6          10   \n",
       "1                      33.333333  18.133333                   3           9   \n",
       "2                      81.818182  38.327273                   9          11   \n",
       "3                      90.000000  42.400000                   9          10   \n",
       "4                      60.000000  29.200000                   6          10   \n",
       "..                           ...        ...                 ...         ...   \n",
       "142                   100.000000  42.400000                   4           4   \n",
       "143                    33.333333  16.133333                   2           6   \n",
       "144                    66.666667  27.866667                   2           3   \n",
       "145                     0.000000   3.200000                   0           7   \n",
       "146                    42.857143  21.142857                   3           7   \n",
       "\n",
       "     SYLLABLE PER WORD  PERSONAL PRONOUNS  AVG WORD LENGTH  \n",
       "0                   28                  0         5.125000  \n",
       "1                   27                  0         6.833333  \n",
       "2                   37                  0         7.642857  \n",
       "3                   35                  0         6.125000  \n",
       "4                   34                  0         7.230769  \n",
       "..                 ...                ...              ...  \n",
       "142                 15                  0         6.166667  \n",
       "143                 15                  0         5.857143  \n",
       "144                  8                  0         7.333333  \n",
       "145                 12                  0         4.500000  \n",
       "146                 17                  0         4.700000  \n",
       "\n",
       "[147 rows x 15 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
